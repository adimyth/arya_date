{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "digits-ocr-kfold.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Vjwc0t-omcPT",
        "Hl7bA8_8mcPl",
        "tLwjjRKomcRH"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cb589164adcf4cbdaa1ab464784af257": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7cf3bbbc2f3d498c8a5ddabe86bad6c9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3aee8c56246a4cb89fba560295f35f26",
              "IPY_MODEL_0501ff8222bd41f59b51c9b2124a0c8d"
            ]
          }
        },
        "7cf3bbbc2f3d498c8a5ddabe86bad6c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3aee8c56246a4cb89fba560295f35f26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_437f0a1324a64de7973fe70a48f3de11",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_67138512927c40ea90aeabe8c6af2713"
          }
        },
        "0501ff8222bd41f59b51c9b2124a0c8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6fd947b9c87040208416e1da353bf379",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1000/1000 [01:39&lt;00:00, 10.03it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_88750d8af35448e08cfb96166f771bdf"
          }
        },
        "437f0a1324a64de7973fe70a48f3de11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "67138512927c40ea90aeabe8c6af2713": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6fd947b9c87040208416e1da353bf379": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "88750d8af35448e08cfb96166f771bdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d05aada53b4e4a15b78203430b71f85e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a0b01d71276541e3af263b2eaeedbb07",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e3016c4a38e44301ac488cd29d47361c",
              "IPY_MODEL_ce916331ce8e43eaba213d2eccc5c9f5"
            ]
          }
        },
        "a0b01d71276541e3af263b2eaeedbb07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e3016c4a38e44301ac488cd29d47361c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2cd65f73773c41889610c89e98e6aaaf",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 10000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 10000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9b1450f950104dccbb9de1ffd217e136"
          }
        },
        "ce916331ce8e43eaba213d2eccc5c9f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_29e1717e8575493885a613b8a520298f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10000/10000 [01:29&lt;00:00, 112.17it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_81975ecf40cb4e3c81c1c19043acb048"
          }
        },
        "2cd65f73773c41889610c89e98e6aaaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9b1450f950104dccbb9de1ffd217e136": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "29e1717e8575493885a613b8a520298f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "81975ecf40cb4e3c81c1c19043acb048": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2e7d0eec5431475881d260064eccd0d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d96a2bc532754642be3df9353c4c0fe7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5d3cf2afe611434cacb0a1d2dd3444e4",
              "IPY_MODEL_356ea67e92814bdab66209c3eb3c7e73"
            ]
          }
        },
        "d96a2bc532754642be3df9353c4c0fe7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5d3cf2afe611434cacb0a1d2dd3444e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_350c2d8b055f4c0ebfe4364266fad9ee",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 39,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 39,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4b2968dadbe74832a58662103479396b"
          }
        },
        "356ea67e92814bdab66209c3eb3c7e73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_37bfdf0630d844baa53f7084c1604f37",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 39/39 [02:58&lt;00:00,  4.58s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c5cd90485ee64bcc893721a855162ce2"
          }
        },
        "350c2d8b055f4c0ebfe4364266fad9ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4b2968dadbe74832a58662103479396b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "37bfdf0630d844baa53f7084c1604f37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c5cd90485ee64bcc893721a855162ce2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f951e8d26e1644db80db7c64637eb9ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5d592b3d15394369bd23a9babfe4c8cd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f1481b99d76049ef9f24e823affd6f05",
              "IPY_MODEL_5a0250f2e9a44d37be50942ab6e56281"
            ]
          }
        },
        "5d592b3d15394369bd23a9babfe4c8cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f1481b99d76049ef9f24e823affd6f05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ef35b5b2c35f45dc9e7e4ab1c09ac690",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 403,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 403,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b22d0763157d41bb801346be03d821ea"
          }
        },
        "5a0250f2e9a44d37be50942ab6e56281": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d64f9d1545534050aa07edaf4c460ff2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 403/403 [00:05&lt;00:00, 80.39it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4729d61fd5624dd4a2d58937bbb227f2"
          }
        },
        "ef35b5b2c35f45dc9e7e4ab1c09ac690": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b22d0763157d41bb801346be03d821ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d64f9d1545534050aa07edaf4c460ff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4729d61fd5624dd4a2d58937bbb227f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adimyth/arya_date/blob/master/notebooks/digits_ocr_kfold_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6r-VD17mcF-"
      },
      "source": [
        "# Digits OCR\n",
        "\n",
        "Source - https://www.kaggle.com/aakashnain/building-a-captcha-ocr-in-tf2-0/notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "HNBqFqZrmcGA"
      },
      "source": [
        "!pip install -q iterative-stratification"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wlp22KsimcGH"
      },
      "source": [
        "## Creating Data Structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "id": "RUAdv4i7mcGI",
        "outputId": "f9cf8c9f-7bab-4ce4-a402-2a24b2dced49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!mkdir data\n",
        "%cd data\n",
        "!mkdir raw external processed\n",
        "!mkdir processed/train processed/test"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "id": "_OPSW-0ImcGT",
        "outputId": "79dd8e93-daf5-493a-aed9-6387b7ca83bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!apt-get -qq install tree"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selecting previously unselected package tree.\n",
            "(Reading database ... 144628 files and directories currently installed.)\n",
            "Preparing to unpack .../tree_1.7.0-5_amd64.deb ...\n",
            "Unpacking tree (1.7.0-5) ...\n",
            "Setting up tree (1.7.0-5) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zCrKBAvTmcGZ",
        "outputId": "a36b7015-da6e-47d5-b7c7-a5b9336754a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!tree ."
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".\n",
            "├── external\n",
            "├── processed\n",
            "│   ├── test\n",
            "│   └── train\n",
            "└── raw\n",
            "\n",
            "5 directories, 0 files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9etpI3emcGe"
      },
      "source": [
        "## Downloading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "q4NBkDZhmcGf"
      },
      "source": [
        "!wget -q http://13.234.225.243:9600/train_data.tar -O external/train_data.tar"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "903v7uz3mcGk"
      },
      "source": [
        "!wget -q http://13.234.225.243:9600/test_data.tar -O external/test_data.tar "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "YT2DhC8cmcGp"
      },
      "source": [
        "!tar -xf external/train_data.tar -C raw/"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "AVTqAd9-mcGt"
      },
      "source": [
        "!tar -xf external/test_data.tar -C raw/"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3unKerQfmcGx"
      },
      "source": [
        "!wget -q http://13.234.225.243:9600/train_data.csv -O raw/train_data/train_data.csv"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "MHSANO6WmcG1"
      },
      "source": [
        "!wget -q http://13.234.225.243:9600/sample_submission.csv -O raw/test_data/sample_submission.csv"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "PoYxZL-jmcG5"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuQpfR72mcHD"
      },
      "source": [
        "## Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "PdrB1LEjmcHD"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vLCL_kucmcHI"
      },
      "source": [
        "sns.set_style(\"darkgrid\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "DhGwAgyomcHN"
      },
      "source": [
        "def plot_grid(images, labels=None, h=5, w=5, title=\"\"):\n",
        "    f, ax = plt.subplots(h, w, figsize=(18, 18))\n",
        "    random_indexes = random.sample(range(len(images)), k=h*w)\n",
        "    for i, j in enumerate(random_indexes):\n",
        "        ax[i // h, i % w].imshow(images[i])\n",
        "        ax[i // h, i % w].axis(\"off\")\n",
        "        ax[i // h, i % w].set_title(labels[i], fontdict={\"fontsize\": 20})\n",
        "    plt.tight_layout()\n",
        "    plt.suptitle(title)\n",
        "    plt.show()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fQCMW-uymcHR"
      },
      "source": [
        "def plot_hist(hist):\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.plot(hist.history[\"loss\"])\n",
        "    plt.plot(hist.history[\"val_loss\"])\n",
        "    plt.title(\"Loss Plot\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.legend([\"Train\", \"Validation\"], loc=\"upper left\")\n",
        "    plt.show()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TySZnwvmcHX"
      },
      "source": [
        "## Extract DateField"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bxGSv6FOmcHY"
      },
      "source": [
        "from glob import glob\n",
        "\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "class ExtractRectangle:\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.minLinLength_h = 70\n",
        "        self.minLinLength_v = 5\n",
        "        self.maxLineGap = 20\n",
        "        self.heights = []\n",
        "        self.widths = []\n",
        "        self.paths = []\n",
        "\n",
        "    def is_horizontal(self, line, thresh=5):\n",
        "        return abs(line[1] - line[3]) <= thresh\n",
        "\n",
        "    def is_vertical(self, line, thresh=5):\n",
        "        return abs(line[0] - line[2]) <= thresh\n",
        "\n",
        "    def get_lines(self, canny, horizontal=True):\n",
        "        lines = []\n",
        "        if horizontal:\n",
        "            linesP = cv.HoughLinesP(\n",
        "                canny,\n",
        "                rho=1,\n",
        "                theta=np.pi / 180,\n",
        "                threshold=10,\n",
        "                lines=None,\n",
        "                minLineLength=self.minLinLength_h,\n",
        "                maxLineGap=20,\n",
        "            )\n",
        "        else:\n",
        "            linesP = cv.HoughLinesP(\n",
        "                canny,\n",
        "                rho=1,\n",
        "                theta=np.pi / 180,\n",
        "                threshold=10,\n",
        "                lines=None,\n",
        "                minLineLength=self.minLinLength_v,\n",
        "                maxLineGap=20,\n",
        "            )\n",
        "        if linesP is not None:\n",
        "            for i in range(0, len(linesP)):\n",
        "                l = linesP[i][0]\n",
        "                if self.is_horizontal(l, 3) and horizontal:\n",
        "                    lines.append(l)\n",
        "                elif self.is_vertical(l, 3):\n",
        "                    lines.append(l)\n",
        "        return lines\n",
        "\n",
        "    def remove_whitespace(self, img):\n",
        "        # https://stackoverflow.com/questions/48395434/how-to-crop-or-remove-white-background-from-an-image\n",
        "        gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "        th, threshed = cv.threshold(gray, 127, 255, cv.THRESH_BINARY_INV)\n",
        "\n",
        "        kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE, (11, 11))\n",
        "        morphed = cv.morphologyEx(threshed, cv.MORPH_CLOSE, kernel)\n",
        "\n",
        "        cnts = cv.findContours(morphed, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)[-2]\n",
        "        cnt = sorted(cnts, key=cv.contourArea)[-1]\n",
        "\n",
        "        x, y, w, h = cv.boundingRect(cnt)\n",
        "        dst = img[y : y + h, x : x + w]\n",
        "        return dst\n",
        "\n",
        "    def process_image(self, filename, path):\n",
        "        errenous = False\n",
        "        img = cv.imread(cv.samples.findFile(filename))\n",
        "        img = self.remove_whitespace(img)\n",
        "        cImage = np.copy(img)\n",
        "\n",
        "        gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "        canny = cv.Canny(gray, 100, 200)\n",
        "\n",
        "        horizontal_lines = self.get_lines(canny)\n",
        "        horizontal_lines = sorted(horizontal_lines, key=lambda a_entry: a_entry[..., 1])\n",
        "\n",
        "        vertical_lines = self.get_lines(canny, horizontal=False)\n",
        "        vertical_lines = sorted(vertical_lines, key=lambda a_entry: a_entry[..., 0])\n",
        "\n",
        "        if len(horizontal_lines) > 0:\n",
        "            initial_line = horizontal_lines[0]\n",
        "            final_line = horizontal_lines[-1]\n",
        "\n",
        "            # LeftTop(x1, y1) -> RightTop(x2, y1) -> RightBottom(x2, y2) -> LeftBottom(x1, y2)\n",
        "            y1 = initial_line[1]\n",
        "            y2 = final_line[1]\n",
        "            bottom = min(y1, y2)\n",
        "            top = max(y1, y2)\n",
        "\n",
        "            # post whitespace removal, dates should only be the major component\n",
        "            if (top - bottom) / img.shape[0] < 0.6:\n",
        "                errenous = True\n",
        "        else:\n",
        "            errenous = True\n",
        "\n",
        "        if len(vertical_lines) > 0:\n",
        "            initial_line = vertical_lines[0]\n",
        "            final_line = vertical_lines[-1]\n",
        "\n",
        "            x1 = initial_line[0]\n",
        "            x2 = final_line[0]\n",
        "            left = min(x1, x2)\n",
        "            right = max(x1, x2)\n",
        "\n",
        "            # as dates occupy majority of the horizontal space\n",
        "            if (right - left) / img.shape[1] <= 0.98:\n",
        "                errenous = True\n",
        "        else:\n",
        "            errenous = True\n",
        "\n",
        "        if not errenous:\n",
        "            # cImage = cv.rectangle(cImage, (left, bottom), (right, top), (255, 0, 0), 2)\n",
        "            cImage = cImage[\n",
        "                bottom : bottom + (top - bottom), left : left + (right - left)\n",
        "            ]\n",
        "            self.paths.append(filename)\n",
        "            self.heights.append(top - bottom)\n",
        "            self.widths.append(right - left)\n",
        "        cv.imwrite(f\"{path}/{filename.split('/')[-1]}\", cImage)\n",
        "\n",
        "    def save_crop_info(self):\n",
        "        df = pd.DataFrame(\n",
        "            {\"path\": self.paths, \"height\": self.heights, \"width\": self.widths}\n",
        "        )\n",
        "        df.to_csv(\"cropped_image_info.csv\", index=False)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "iugZ3ahEmcHd",
        "outputId": "ac13c423-4b35-4c3c-9b19-ca7d0b93f5a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "cb589164adcf4cbdaa1ab464784af257",
            "7cf3bbbc2f3d498c8a5ddabe86bad6c9",
            "3aee8c56246a4cb89fba560295f35f26",
            "0501ff8222bd41f59b51c9b2124a0c8d",
            "437f0a1324a64de7973fe70a48f3de11",
            "67138512927c40ea90aeabe8c6af2713",
            "6fd947b9c87040208416e1da353bf379",
            "88750d8af35448e08cfb96166f771bdf",
            "d05aada53b4e4a15b78203430b71f85e",
            "a0b01d71276541e3af263b2eaeedbb07",
            "e3016c4a38e44301ac488cd29d47361c",
            "ce916331ce8e43eaba213d2eccc5c9f5",
            "2cd65f73773c41889610c89e98e6aaaf",
            "9b1450f950104dccbb9de1ffd217e136",
            "29e1717e8575493885a613b8a520298f",
            "81975ecf40cb4e3c81c1c19043acb048"
          ]
        }
      },
      "source": [
        "extract = ExtractRectangle()\n",
        "test_files = glob(\"raw/test_data/*.png\")\n",
        "test_path = \"processed/test/\"\n",
        "for path in tqdm(test_files):\n",
        "    extract.process_image(path, test_path)\n",
        "\n",
        "train_files = glob(\"raw/train_data/*.png\")\n",
        "train_path = \"processed/train/\"\n",
        "for path in tqdm(train_files):\n",
        "    extract.process_image(path, train_path)\n",
        "\n",
        "# saving crop info\n",
        "extract.save_crop_info()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb589164adcf4cbdaa1ab464784af257",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d05aada53b4e4a15b78203430b71f85e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "hsS0qHCAmcHm"
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iL87y-FmcHq"
      },
      "source": [
        "## Augment Data\n",
        "**Method 1**\n",
        "\n",
        "Crop cleaned images above such that 2 images with same areas are combined in the following way -\n",
        "* Combine x digits of first image & y digits of second image such that x+y=8.\n",
        "* Here, I loop from digits 1 to 4. That gives for a pair with same areas - 4 images\n",
        "\n",
        "Combine the images in following ways -\n",
        "* Initial part of both images\n",
        "* Last part of first image & initial part of second image\n",
        "* Initial part of first image & last part of second image\n",
        "* Last part of both images\n",
        "\n",
        "**Method 2**\n",
        "\n",
        "For each image, take the first x digit & first y digits & stitch them horizontally. Loop x from 1-7, this mostly eliminates the last section of the image which only has [771, 781, 871, 881] as the last 3 digits in the original training data, hence creating some variation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ReeTTg7bmcHr"
      },
      "source": [
        "import itertools\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "class DataAugmenter:\n",
        "    def __init__(self):\n",
        "        super(DataAugmenter).__init__()\n",
        "        self.aug_path = []\n",
        "        self.aug_labels = []\n",
        "        train_data = pd.read_csv(\"raw/train_data/train_data.csv\")[[\"tag\", \"label\"]]\n",
        "        train_data[\"label\"] = train_data[\"label\"].astype(str).str.zfill(8)\n",
        "        self.train_data = dict(\n",
        "            zip(train_data[\"tag\"].tolist(), train_data[\"label\"].tolist())\n",
        "        )\n",
        "        self.count = 10000\n",
        "\n",
        "    def stitch_images_horizontally(\n",
        "        self,\n",
        "        inp_files,\n",
        "        save_path,\n",
        "        height,\n",
        "        width,\n",
        "        digits1=4,\n",
        "        digits2=4,\n",
        "        comb_type=\"type1\",\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Crops & stitches two images.\n",
        "        Crops initial `digit1` & initial `digit2` digits from corresponding images & stitches them horizontally\n",
        "\n",
        "        Arguments\n",
        "        ---------\n",
        "        inp_files - list\n",
        "            List of image pair paths\n",
        "\n",
        "        height - int\n",
        "            Image height for both images.\n",
        "\n",
        "        width - int\n",
        "            Image width for both images\n",
        "\n",
        "        digit1 - int\n",
        "            Number of digits to take from first image\n",
        "\n",
        "        digit2 - int\n",
        "            Number of digits to take from second image\n",
        "\n",
        "        comb_type - str\n",
        "            Denotes combination type.\n",
        "            type1 - Initial part of both images\n",
        "            type2 - Last part of first image & initial part of second image\n",
        "            type3 - Initial part of first image & last part of second image\n",
        "            type4 - Last part of both images\n",
        "        \"\"\"\n",
        "\n",
        "        images = [Image.open(x) for x in inp_files]\n",
        "\n",
        "        w1 = int(width * (digits1 / 8))\n",
        "        w2 = int(width * (digits2 / 8))\n",
        "\n",
        "        if comb_type == \"type1\":\n",
        "            img1_crop = images[0].crop((0, 0, w1, height))\n",
        "            img2_crop = images[1].crop((0, 0, w2, height))\n",
        "            images = [img1_crop, img2_crop]\n",
        "        elif comb_type == \"type2\":\n",
        "            img1_crop = images[0].crop((w1, 0, width, height))\n",
        "            img2_crop = images[1].crop((0, 0, w2, height))\n",
        "            images = [img1_crop, img2_crop]\n",
        "        elif comb_type == \"type3\":\n",
        "            img1_crop = images[0].crop((0, 0, w1, height))\n",
        "            img2_crop = images[1].crop((w2, 0, width, height))\n",
        "            images = [img1_crop, img2_crop]\n",
        "        elif comb_type == \"type4\":\n",
        "            img1_crop = images[0].crop((w1, 0, width, height))\n",
        "            img2_crop = images[1].crop((w2, 0, width, height))\n",
        "            images = [img1_crop, img2_crop]\n",
        "\n",
        "        widths, heights = zip(*(i.size for i in images))\n",
        "        total_width = sum(widths)\n",
        "        max_height = min(heights)\n",
        "\n",
        "        new_im = Image.new(\"RGB\", (total_width, max_height))\n",
        "\n",
        "        x_offset = 0\n",
        "        for im in images:\n",
        "            new_im.paste(im, (x_offset, 0))\n",
        "            x_offset += im.size[0]\n",
        "        new_im.save(save_path)\n",
        "\n",
        "    def process(self):\n",
        "        df = pd.read_csv(\"cropped_image_info.csv\")\n",
        "        df[\"area\"] = df[\"height\"].multiply(df[\"width\"])\n",
        "        df = df.loc[df[\"path\"].str.contains(\"train\")]\n",
        "        df[\"tag\"] = df[\"path\"].apply(lambda x: int(x.split(\"/\")[-1].split(\".\")[0]))\n",
        "        df = df.sort_values(by=\"tag\")\n",
        "        df[\"path\"] = df[\"path\"].str.replace(\"raw/train_data/\", \"processed/train/\")\n",
        "        temp = dict(zip(df[\"tag\"].tolist(), df[\"path\"].tolist()))\n",
        "\n",
        "        # find matching areas\n",
        "        matching_areas = df[\"area\"].value_counts()\n",
        "        matching_areas = matching_areas[matching_areas > 2].index.tolist()\n",
        "        # loop over matching areas\n",
        "        for area in tqdm(matching_areas):\n",
        "            # get height & width\n",
        "            height = df.loc[df[\"area\"] == area][\"height\"].iloc[0]\n",
        "            width = df.loc[df[\"area\"] == area][\"width\"].iloc[0]\n",
        "            # create permutation based on tag\n",
        "            all_combinations = list(\n",
        "                itertools.combinations(\n",
        "                    df.loc[df[\"area\"] == area][\"tag\"].tolist()[:3], 2\n",
        "                )\n",
        "            )\n",
        "            # for each combination\n",
        "            for comb in all_combinations:\n",
        "                tag1, tag2 = comb[0], comb[1]\n",
        "                image1 = temp[tag1]\n",
        "                image2 = temp[tag2]\n",
        "                label1 = self.train_data[tag1]\n",
        "                label2 = self.train_data[tag2]\n",
        "\n",
        "                # variation based on number of digits per image - type1\n",
        "                for digit1 in range(1, 7):\n",
        "                    digit2 = 8 - digit1\n",
        "                    self.count += 1\n",
        "                    path = f\"processed/train/{self.count}.png\"\n",
        "                    label = str(label1)[:digit1] + str(label2)[:digit2]\n",
        "                    self.stitch_images_horizontally(\n",
        "                        [image1, image2], path, height, width, digit1, digit2\n",
        "                    )\n",
        "\n",
        "                    self.aug_labels.append(label)\n",
        "                    self.aug_path.append(path)\n",
        "\n",
        "                # different types\n",
        "                for comb_type in [\"type2\", \"type3\", \"type4\"]:\n",
        "                    self.count += 1\n",
        "                    path = f\"processed/train/{self.count}.png\"\n",
        "                    if comb_type == \"type2\":\n",
        "                        label = str(label1)[4:] + str(label2)[:4]\n",
        "                    elif comb_type == \"type3\":\n",
        "                        label = str(label1)[:4] + str(label2)[4:]\n",
        "                    elif comb_type == \"type4\":\n",
        "                        label = str(label1)[4:] + str(label2)[4:]\n",
        "\n",
        "                    self.stitch_images_horizontally(\n",
        "                        [image1, image2], path, height, width, comb_type=comb_type\n",
        "                    )\n",
        "                    self.aug_labels.append(label)\n",
        "                    self.aug_path.append(path)\n",
        "\n",
        "    def add_reverse(self):\n",
        "        df = pd.read_csv(\"cropped_image_info.csv\")\n",
        "        df = df.loc[df[\"path\"].str.contains(\"train\")]\n",
        "        df[\"tag\"] = df[\"path\"].apply(lambda x: int(x.split(\"/\")[-1].split(\".\")[0]))\n",
        "        df = df.sort_values(by=\"tag\")\n",
        "        df[\"path\"] = df[\"path\"].str.replace(\"raw/train_data/\", \"processed/train/\")\n",
        "        image_temp = dict(zip(df[\"tag\"].tolist(), df[\"path\"].tolist()))\n",
        "        height_temp = dict(zip(df[\"tag\"].tolist(), df[\"height\"].tolist()))\n",
        "        width_temp = dict(zip(df[\"tag\"].tolist(), df[\"width\"].tolist()))\n",
        "        actual_df = pd.read_csv(\"raw/train_data/train_data.csv\")\n",
        "        actual_df = actual_df[[\"tag\", \"label\"]]\n",
        "\n",
        "        for tag in tqdm(df[\"tag\"].tolist()):\n",
        "            image = image_temp[tag]\n",
        "            height = height_temp[tag]\n",
        "            width = width_temp[tag]\n",
        "            act_label = str(\n",
        "                actual_df.loc[actual_df[\"tag\"] == tag][\"label\"].tolist()[0]\n",
        "            ).zfill(8)\n",
        "\n",
        "            # variation based on number of digits per image - type1\n",
        "            for digit1 in range(1, 7):\n",
        "                digit2 = 8 - digit1\n",
        "                self.count += 1\n",
        "                path = f\"processed/train/{self.count}.png\"\n",
        "                label = str(act_label)[:digit1] + str(act_label)[:digit2]\n",
        "                self.stitch_images_horizontally(\n",
        "                    [image, image], path, height, width, digit1, digit2\n",
        "                )\n",
        "\n",
        "                self.aug_labels.append(label)\n",
        "                self.aug_path.append(path)\n",
        "        updated_train_data = pd.DataFrame.from_dict(\n",
        "            {\"tag\": self.aug_path, \"label\": self.aug_labels}\n",
        "        )\n",
        "        updated_train_data.to_csv(\"updated_train_data.csv\", index=False)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GulZM-H2mcHw",
        "outputId": "5137f646-d093-43c6-9402-c80e585f83fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149,
          "referenced_widgets": [
            "2e7d0eec5431475881d260064eccd0d7",
            "d96a2bc532754642be3df9353c4c0fe7",
            "5d3cf2afe611434cacb0a1d2dd3444e4",
            "356ea67e92814bdab66209c3eb3c7e73",
            "350c2d8b055f4c0ebfe4364266fad9ee",
            "4b2968dadbe74832a58662103479396b",
            "37bfdf0630d844baa53f7084c1604f37",
            "c5cd90485ee64bcc893721a855162ce2",
            "f951e8d26e1644db80db7c64637eb9ef",
            "5d592b3d15394369bd23a9babfe4c8cd",
            "f1481b99d76049ef9f24e823affd6f05",
            "5a0250f2e9a44d37be50942ab6e56281",
            "ef35b5b2c35f45dc9e7e4ab1c09ac690",
            "b22d0763157d41bb801346be03d821ea",
            "d64f9d1545534050aa07edaf4c460ff2",
            "4729d61fd5624dd4a2d58937bbb227f2"
          ]
        }
      },
      "source": [
        "augment = DataAugmenter()\n",
        "augment.process()\n",
        "x = augment.count\n",
        "print(f\"# AUGMENTED IMAGES: {x - 10000}\")\n",
        "augment.add_reverse()\n",
        "print(f\"# REVERSE IMAGES: {augment.count - x}\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e7d0eec5431475881d260064eccd0d7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=39.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "# AUGMENTED IMAGES: 1053\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f951e8d26e1644db80db7c64637eb9ef",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=403.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "# REVERSE IMAGES: 2418\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Qt9vCHVnmcHz"
      },
      "source": [
        ""
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ej0iFH7emcH3"
      },
      "source": [
        "## Digits OCR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyY4gx9JsrI3",
        "outputId": "b4c2b18b-0fb0-49b2-adff-d1eba3c05972",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd data"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'data'\n",
            "/content/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LYEaKcUsmcH4",
        "outputId": "a0c5f082-e14f-42f3-e287-9f768674b172",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from itertools import chain\n",
        "import os\n",
        "from pprint import pprint\n",
        "import random\n",
        "import requests\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print(\"Tensorflow version: \", tf.__version__)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version:  2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "f51SypuemcH7"
      },
      "source": [
        "TEST_IMAGES_PATH = \"processed/test/\"\n",
        "TRAIN_CSV_PATH = \"updated_train_data.csv\"\n",
        "TRAIN_IMAGES_PATH = \"processed/train/\""
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "soE7600JmcH-"
      },
      "source": [
        "RANDOM_STATE = 42\n",
        "NUM_SPLITS = 3"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "h543yQEtmcIC"
      },
      "source": [
        "PUBLIC_host = \"http://13.234.225.243\"\n",
        "SUBMISSION_URL = PUBLIC_host + \":8080/submit\"\n",
        "LEADERBOARD_URL = PUBLIC_host + \":8080/leaderboard\"\n",
        "DATA_URL = PUBLIC_host + \":9600\"\n",
        "TAG = \"image_captioning_v1\""
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_HWN33hDmcIG"
      },
      "source": [
        "def seed_everything(seed):\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    os.environ[\"TF_DETERMINISTIC_OPS\"] = str(seed)\n",
        "\n",
        "seed_everything(RANDOM_STATE)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "UfFw8wW-mcIK",
        "outputId": "2fe6e025-a477-42b1-f92f-560e30bc9c48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data_dir = Path(\"processed/train/\")\n",
        "images = list(data_dir.glob(\"*.png\"))\n",
        "print(f\"# Training Images: {len(images)}\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Training Images: 13471\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "noox42s3mcIO",
        "outputId": "597e0520-4d35-4544-ffdd-4113e4f00746",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_data_dir = Path(\"processed/test/\")\n",
        "test_images = list(test_data_dir.glob(\"*.png\"))\n",
        "print(f\"# Test Images: {len(test_images)}\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Test Images: 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8fiKpCq9mcIS"
      },
      "source": [
        "df = pd.read_csv(TRAIN_CSV_PATH)\n",
        "x = pd.read_csv(\"raw/train_data/train_data.csv\")"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ISBEovYfmcIX"
      },
      "source": [
        "df[\"tag\"] = df[\"tag\"].apply(lambda x: int(x.split(\"/\")[-1].split(\".\")[0]))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bg3mIidbmcIa"
      },
      "source": [
        "df = df.append(x)\n",
        "df[\"tag\"] = df[\"tag\"].astype(int)\n",
        "df = df.sort_values(by=\"tag\")"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ZjrYflSsmcIj"
      },
      "source": [
        "df[\"label\"] = df[\"label\"].astype(str)\n",
        "df[\"label\"] = df[\"label\"].str.zfill(8)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ey5S9z7LmcIn"
      },
      "source": [
        "characters = set()\n",
        "captcha_length = []\n",
        "dataset = []"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "foT3m9iUmcJN"
      },
      "source": [
        "for img_path in images:\n",
        "    label = df.loc[df[\"tag\"]==int(img_path.stem)][\"label\"].tolist()[0]\n",
        "    captcha_length.append(len(label))\n",
        "    dataset.append((str(img_path), label))\n",
        "\n",
        "    for ch in label:\n",
        "        characters.add(ch)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2_5hYxJHmcJq",
        "outputId": "8b2a3a06-c89c-46c3-9d47-68bf48fb2fcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "characters = sorted(characters)\n",
        "dataset = pd.DataFrame(dataset, columns=[\"img_path\", \"label\"], index=None)\n",
        "dataset = dataset.sample(frac=1.).reset_index(drop=True)\n",
        "\n",
        "print(f\"# Unique Characters: {len(characters)}\")\n",
        "print(f\"Max Length: {max(Counter(captcha_length).keys())}\")\n",
        "print(f\"Digits Present: {characters}\")\n",
        "print(f\"# Samples: {len(dataset)}\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Unique Characters: 10\n",
            "Max Length: 8\n",
            "Digits Present: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
            "# Samples: 13471\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "QsvsZhI0mcLm"
      },
      "source": [
        "# digits distribution\n",
        "for i in range(10):\n",
        "    dataset[i] = dataset[\"label\"].str.count(str(i))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "k0YdXfXJmcLs",
        "outputId": "8d1f49fe-ce10-4d42-dd1e-d51249c53051",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>img_path</th>\n",
              "      <th>label</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>processed/train/12439.png</td>\n",
              "      <td>69693869</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>processed/train/3990.png</td>\n",
              "      <td>02983871</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>processed/train/9862.png</td>\n",
              "      <td>60416781</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>processed/train/11365.png</td>\n",
              "      <td>51644851</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>processed/train/1064.png</td>\n",
              "      <td>32096771</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    img_path     label  0  1  2  3  4  5  6  7  8  9\n",
              "0  processed/train/12439.png  69693869  0  0  0  1  0  0  3  0  1  3\n",
              "1   processed/train/3990.png  02983871  1  1  1  1  0  0  0  1  2  1\n",
              "2   processed/train/9862.png  60416781  1  2  0  0  1  0  2  1  1  0\n",
              "3  processed/train/11365.png  51644851  0  2  0  0  2  2  1  0  1  0\n",
              "4   processed/train/1064.png  32096771  1  1  1  1  0  0  1  2  0  1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yltwGxshmcL0",
        "outputId": "e947aa44-d019-4703-cc8f-ce7c5a7982fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i in range(10):\n",
        "    print(f\"{i} - {dataset[i].sum()}\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 - 5820\n",
            "1 - 16689\n",
            "2 - 8632\n",
            "3 - 8897\n",
            "4 - 8688\n",
            "5 - 8965\n",
            "6 - 8762\n",
            "7 - 17845\n",
            "8 - 17314\n",
            "9 - 6156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "iYatjxoTmcL5"
      },
      "source": [
        "char_to_labels = {char:idx for idx, char in enumerate(characters)}\n",
        "labels_to_char = {val:key for key, val in char_to_labels.items()}"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jjbH8Q1VmcL-"
      },
      "source": [
        "def is_valid_captcha(captcha):\n",
        "    for ch in captcha:\n",
        "        if not ch in characters:\n",
        "            return False\n",
        "    return True"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "dXtPFMDMmcMH"
      },
      "source": [
        "def generate_arrays(df, resize=True, img_height=100, img_width=450):\n",
        "    \"\"\"Generates image array and labels array from a dataframe.\n",
        "    \n",
        "    Args:\n",
        "        df: dataframe from which we want to read the data\n",
        "        resize (bool)    : whether to resize images or not\n",
        "        img_weidth (int): width of the resized images\n",
        "        img_height (int): height of the resized images\n",
        "        \n",
        "    Returns:\n",
        "        images (ndarray): grayscale images\n",
        "        labels (ndarray): corresponding encoded labels\n",
        "    \"\"\"\n",
        "    \n",
        "    num_items = len(df)\n",
        "    images = np.zeros((num_items, img_height, img_width), dtype=np.float32)\n",
        "    labels = [0]*num_items\n",
        "    \n",
        "    for i in range(num_items):\n",
        "        img = cv2.imread(df[\"img_path\"][i])\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        \n",
        "        if resize: \n",
        "            img = cv2.resize(img, (img_width, img_height))\n",
        "        \n",
        "        img = (img/255.).astype(np.float32)\n",
        "        label = df[\"label\"][i]\n",
        "        \n",
        "        # Add only if it is a valid captcha\n",
        "        if is_valid_captcha(label):\n",
        "            images[i, :, :] = img\n",
        "            labels[i] = label\n",
        "    \n",
        "    return images, np.array(labels)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "pDgO8O10mcMK"
      },
      "source": [
        ""
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iij2_Dx0mcMN"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "eLLWZqSKmcMP"
      },
      "source": [
        "class CTCLayer(layers.Layer):\n",
        "    def __init__(self, name=None):\n",
        "        super().__init__(name=name)\n",
        "        self.loss_fn = keras.backend.ctc_batch_cost\n",
        "\n",
        "    def call(self, y_true, y_pred, input_length, label_length):\n",
        "        # Compute the training-time loss value and add it\n",
        "        # to the layer using `self.add_loss()`.\n",
        "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
        "        self.add_loss(loss)\n",
        "        \n",
        "        # On test time, just return the computed loss\n",
        "        return loss"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "g3T4V0I7mcMR"
      },
      "source": [
        "def build_model():\n",
        "    # Inputs to the model\n",
        "    input_img = layers.Input(shape=(img_width, img_height, 1),\n",
        "                            name='input_data',\n",
        "                            dtype='float32')\n",
        "    labels = layers.Input(name='input_label', shape=[max_length], dtype='float32')\n",
        "    input_length = layers.Input(name='input_length', shape=[1], dtype='int64')\n",
        "    label_length = layers.Input(name='label_length', shape=[1], dtype='int64')\n",
        "    \n",
        "    # First conv block\n",
        "    x = layers.Conv2D(32,\n",
        "               (3,3),\n",
        "               activation='relu',\n",
        "               kernel_initializer='he_normal',\n",
        "               padding='same',\n",
        "               name='Conv1')(input_img)\n",
        "    x = layers.MaxPooling2D((2,2), name='pool1')(x)\n",
        "    \n",
        "    # Second conv block\n",
        "    x = layers.Conv2D(64,\n",
        "               (3,3),\n",
        "               activation='relu',\n",
        "               kernel_initializer='he_normal',\n",
        "               padding='same',\n",
        "               name='Conv2')(x)\n",
        "    x = layers.MaxPooling2D((2,2), name='pool2')(x)\n",
        "    \n",
        "    # We have used two max pool with pool size and strides of 2.\n",
        "    # Hence, downsampled feature maps are 4x smaller. The number of\n",
        "    # filters in the last layer is 64. Reshape accordingly before\n",
        "    # passing it to RNNs\n",
        "    new_shape = ((img_width // 4), (img_height // 4)*64)\n",
        "    x = layers.Reshape(target_shape=new_shape, name='reshape')(x)\n",
        "    x = layers.Dense(64, activation='relu', name='dense1')(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    \n",
        "    # RNNs\n",
        "    x = layers.Bidirectional(layers.LSTM(128,\n",
        "                                         return_sequences=True,\n",
        "                                         dropout=0.2))(x)\n",
        "    x = layers.Bidirectional(layers.LSTM(64,\n",
        "                                         return_sequences=True,\n",
        "                                         dropout=0.25))(x)\n",
        "    \n",
        "    # Predictions\n",
        "    x = layers.Dense(len(characters)+1,\n",
        "              activation='softmax', \n",
        "              name='dense2',\n",
        "              kernel_initializer='he_normal')(x)\n",
        "    \n",
        "    # Calculate CTC\n",
        "    output = CTCLayer(name='ctc_loss')(labels, x, input_length, label_length)\n",
        "    \n",
        "    # Define the model\n",
        "    model = keras.models.Model(inputs=[input_img,\n",
        "                                       labels,\n",
        "                                       input_length,\n",
        "                                       label_length],\n",
        "                                outputs=output,\n",
        "                                name='ocr_model_v1')\n",
        "    \n",
        "    # Optimizer\n",
        "    sgd = keras.optimizers.SGD(learning_rate=0.002,\n",
        "                               decay=1e-6,\n",
        "                               momentum=0.9,\n",
        "                               nesterov=True,\n",
        "                               clipnorm=5)\n",
        "    \n",
        "    # Compile the model and return \n",
        "    model.compile(optimizer=sgd)\n",
        "    return model"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "95yFt-rVmcMb"
      },
      "source": [
        ""
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLihcf1rmcMn"
      },
      "source": [
        "### DataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "YbV3JnhrmcMo"
      },
      "source": [
        "class DataGenerator(keras.utils.Sequence):\n",
        "    \"\"\"Generates batches from a given dataset.\n",
        "\n",
        "    Args:\n",
        "        data: training or validation data\n",
        "        labels: corresponding labels\n",
        "        char_map: dictionary mapping char to labels\n",
        "        batch_size: size of a single batch\n",
        "        img_width: width of the resized\n",
        "        img_height: height of the resized\n",
        "        downsample_factor: by what factor did the CNN downsample the images\n",
        "        max_length: maximum length of any captcha\n",
        "        shuffle: whether to shuffle data or not after each epoch\n",
        "    Returns:\n",
        "        batch_inputs: a dictionary containing batch inputs\n",
        "        batch_labels: a batch of corresponding labels\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        data,\n",
        "        labels,\n",
        "        char_map,\n",
        "        batch_size=16,\n",
        "        img_width=450,\n",
        "        img_height=100,\n",
        "        downsample_factor=4,\n",
        "        max_length=5,\n",
        "        shuffle=True,\n",
        "    ):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.char_map = char_map\n",
        "        self.batch_size = batch_size\n",
        "        self.img_width = img_width\n",
        "        self.img_height = img_height\n",
        "        self.downsample_factor = downsample_factor\n",
        "        self.max_length = max_length\n",
        "        self.shuffle = shuffle\n",
        "        self.indices = np.arange(len(data))\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.data) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # 1. Get the next batch indices\n",
        "        curr_batch_idx = self.indices[\n",
        "            idx * self.batch_size : (idx + 1) * self.batch_size\n",
        "        ]\n",
        "\n",
        "        # 2. This isn't necessary but it can help us save some memory\n",
        "        # as not all batches the last batch may not have elements\n",
        "        # equal to the batch_size\n",
        "        batch_len = len(curr_batch_idx)\n",
        "\n",
        "        # 3. Instantiate batch arrays\n",
        "        batch_images = np.ones(\n",
        "            (batch_len, self.img_width, self.img_height, 1), dtype=np.float32\n",
        "        )\n",
        "        batch_labels = np.ones((batch_len, self.max_length), dtype=np.float32)\n",
        "        input_length = np.ones((batch_len, 1), dtype=np.int64) * (\n",
        "            self.img_width // self.downsample_factor - 2\n",
        "        )\n",
        "        label_length = np.zeros((batch_len, 1), dtype=np.int64)\n",
        "\n",
        "        for j, idx in enumerate(curr_batch_idx):\n",
        "            # 1. Get the image and transpose it\n",
        "            img = self.data[idx].T\n",
        "            # 2. Add extra dimenison\n",
        "            img = np.expand_dims(img, axis=-1)\n",
        "            # 3. Get the correpsonding label\n",
        "            text = self.labels[idx]\n",
        "            # 4. Include the pair only if the captcha is valid\n",
        "            if is_valid_captcha(text):\n",
        "                label = [self.char_map[ch] for ch in text]\n",
        "                batch_images[j] = img\n",
        "                batch_labels[j] = label\n",
        "                label_length[j] = len(text)\n",
        "\n",
        "        batch_inputs = {\n",
        "            \"input_data\": batch_images,\n",
        "            \"input_label\": batch_labels,\n",
        "            \"input_length\": input_length,\n",
        "            \"label_length\": label_length,\n",
        "        }\n",
        "        return batch_inputs, np.zeros(batch_len).astype(np.float32)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "lD8R_oejmcMq"
      },
      "source": [
        "batch_size = 16\n",
        "downsample_factor = 4\n",
        "epochs = 2\n",
        "max_length = 8\n",
        "\n",
        "img_width = 450\n",
        "img_height = 100"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SwpGJrotmcMx"
      },
      "source": [
        "params = {\"char_map\": char_to_labels, \n",
        "          \"batch_size\": batch_size, \n",
        "          \"img_width\": img_width, \n",
        "          \"img_height\": img_height,\n",
        "          \"downsample_factor\": downsample_factor, \n",
        "          \"max_length\": max_length\n",
        "}"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Y71bcDozmcNK"
      },
      "source": [
        ""
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edDNpme1mcNh"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Ax7IuOO-mcNh"
      },
      "source": [
        "def decode_batch_predictions(pred):\n",
        "    pred = pred[:, :-2]\n",
        "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
        "\n",
        "    # greedy search\n",
        "    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0]\n",
        "\n",
        "    output_text = []\n",
        "    for res in results.numpy():\n",
        "        outstr = \"\"\n",
        "        for c in res:\n",
        "            if c < len(characters) and c >= 0:\n",
        "                outstr += labels_to_char[c]\n",
        "        output_text.append(outstr)\n",
        "\n",
        "    return output_text"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3trQF2eLmcNo"
      },
      "source": [
        "def get_all_preds(prediction_model, data_generator):\n",
        "    \"\"\"\n",
        "    Utility function that returns both model pprediction & actual labels\n",
        "    \"\"\"\n",
        "    decoded_text, actuals_text = [], []\n",
        "    for p, (inp_value, _) in tqdm(enumerate(data_generator)):\n",
        "        bs = inp_value[\"input_data\"].shape[0]\n",
        "        X_data = inp_value[\"input_data\"]\n",
        "        labels = inp_value[\"input_label\"]\n",
        "\n",
        "        preds = prediction_model.predict(X_data)\n",
        "        pred_texts = decode_batch_predictions(preds)\n",
        "\n",
        "        orig_texts = []\n",
        "        for label in labels:\n",
        "            text = \"\".join([labels_to_char[int(x)] for x in label])\n",
        "            orig_texts.append(text)\n",
        "\n",
        "        decoded_text.append([pred_texts[i] for i in range(bs)])\n",
        "        actuals_text.append([orig_texts[i] for i in range(bs)])\n",
        "\n",
        "    print(f\"Before (Preds) {decoded_text}\")\n",
        "    print(f\"Before (Actuals) {actuals_text}\")\n",
        "    # flatten 2D list\n",
        "    decoded_text = list(chain.from_iterable(decoded_text))\n",
        "    actuals_text = list(chain.from_iterable(actuals_text))\n",
        "    print(f\"After (Preds): {decoded_text}\")\n",
        "    print(f\"After (Actuals) {actuals_text}\")\n",
        "    return decoded_text, actuals_text"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "id": "oMi_qU9gmcNr"
      },
      "source": [
        "kfold = MultilabelStratifiedKFold(n_splits=NUM_SPLITS, shuffle=True, random_state=RANDOM_STATE)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7k7vZu1umcNu"
      },
      "source": [
        "# storing labels only\n",
        "dataset = dataset.head(2000)\n",
        "oof_preds = np.array([\"\"]*len(dataset))\n",
        "oof_actuals = np.array([\"\"]*len(dataset))"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SGfBPQhKmcOM",
        "outputId": "5df201db-3de9-4231-f58d-fe0a445a059a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for fold, (train_idx, valid_idx) in enumerate(kfold.split(X=dataset[\"img_path\"], \n",
        "                                                          y=dataset[range(10)])):\n",
        "    print(\"*\"*28)\n",
        "    print(\"*\"+\" \"*10+f\"FOLD {fold}\"+\" \"*10+\"*\")\n",
        "    print(\"*\"*28)\n",
        "\n",
        "    es = keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
        "                                   patience=5,\n",
        "                                   restore_best_weights=True)\n",
        "\n",
        "    training_data = dataset.iloc[train_idx].reset_index(drop=True)\n",
        "    validation_data = dataset.iloc[valid_idx].reset_index(drop=True)\n",
        "    \n",
        "    training_data, training_labels = generate_arrays(df=training_data)\n",
        "    validation_data, validation_labels = generate_arrays(df=validation_data)\n",
        "\n",
        "    train_data_generator = DataGenerator(data=training_data,\n",
        "                                         labels=training_labels,\n",
        "                                         shuffle=True,\n",
        "                                         **params\n",
        "                                        )\n",
        "    valid_data_generator = DataGenerator(data=validation_data,\n",
        "                                         labels=validation_labels,\n",
        "                                         shuffle=False,\n",
        "                                         **params)\n",
        "    tf.keras.backend.clear_session()\n",
        "    model = build_model()\n",
        "    history = model.fit(train_data_generator,\n",
        "                        validation_data=valid_data_generator,\n",
        "                        epochs=epochs,\n",
        "                        callbacks=[es])\n",
        "    plot_hist(history)\n",
        "    model.save(f\"digits_ocr_fold_{fold}.h5\")\n",
        "    \n",
        "    \n",
        "    prediction_model = keras.models.Model(model.get_layer(name=\"input_data\").input, \n",
        "                                          model.get_layer(name=\"dense2\").output)\n",
        "    # get validation preds\n",
        "    decoded_text, actuals_text = get_all_preds(prediction_model, valid_data_generator)\n",
        "    oof_preds[valid_idx] = decoded_text\n",
        "    oof_actuals[valid_idx] = actuals_text\n",
        "    print(f\"Validation Accuracy: {accuracy_score(actuals_text, decoded_text):.4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "****************************\n",
            "*          FOLD 0          *\n",
            "****************************\n",
            "Epoch 1/2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yXiPYKLcmcOl",
        "outputId": "277fd07d-24e9-4e1e-e6f5-a655c03871b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(f\"Training Data Accuracy: {accuracy_score(oof_actuals, oof_preds):.4f}\")"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Data Accuracy: 0.0400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-_ozuStrGaZ",
        "outputId": "047f11c2-9700-4f81-8aea-3a57e120d7bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "oof_preds"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['', '8', '', '', '', '', '', '', '8', '8', '', '', '', '', '', '',\n",
              "       '', '', '', '', '7', '7', '8', '8', '7', '', '', '7', '', '', '',\n",
              "       '', '8', '', '7', '', '8', '', '', '', '', '', '', '8', '7', '',\n",
              "       '', '7', '', '8', '7', '', '', '7', '', '8', '', '', '', '7', '8',\n",
              "       '', '8', '', '', '8', '8', '8', '7', '7', '8', '7', '8', '8', '',\n",
              "       '7', '', '7', '', '', '7', '', '', '7', '8', '', '', '', '', '',\n",
              "       '', '', '7', '', '', '7', '', '', '8', '7'], dtype='<U1')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LK_cbrWtmcOn",
        "outputId": "f38d0197-7048-4cfc-8081-6f19fb23780b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "oof_actuals"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['7', '2', '1', '4', '7', '5', '2', '8', '9', '3', '8', '5', '5',\n",
              "       '7', '1', '5', '4', '3', '4', '1', '3', '3', '6', '7', '9', '9',\n",
              "       '0', '1', '7', '8', '7', '4', '3', '1', '3', '5', '4', '2', '7',\n",
              "       '9', '2', '5', '9', '1', '4', '0', '5', '5', '8', '6', '6', '3',\n",
              "       '5', '3', '5', '5', '0', '9', '7', '7', '7', '7', '2', '7', '3',\n",
              "       '2', '8', '3', '0', '6', '5', '3', '5', '5', '4', '1', '2', '9',\n",
              "       '6', '1', '1', '3', '9', '7', '9', '7', '7', '5', '5', '3', '3',\n",
              "       '7', '9', '9', '8', '6', '7', '1', '8', '6'], dtype='<U1')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "loB594slmcOs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtgAp9XQmcOu"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk0N7368mcOv"
      },
      "source": [
        "* The evaluate function is similar to the training loop, except you don't use teacher forcing here. The input to the decoder at each time step is its previous predictions along with the hidden state and the encoder output.\n",
        "* Stop predicting when the model predicts the end token.\n",
        "* And store the attention weights for every time step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ZCR7UPhbmcOw"
      },
      "source": [
        "prediction_model = keras.models.Model(\n",
        "    model.get_layer(name=\"input_data\").input, model.get_layer(name=\"dense2\").output\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "uJ3eM_XJmcOy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyftNBc9mcO0"
      },
      "source": [
        "### Validation Data Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-78PdgxmcO1"
      },
      "source": [
        "**Greedy Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "abEaWDVImcO2"
      },
      "source": [
        "for p, (inp_value, _) in enumerate(valid_data_generator):\n",
        "    bs = inp_value[\"input_data\"].shape[0]\n",
        "    X_data = inp_value[\"input_data\"]\n",
        "    labels = inp_value[\"input_label\"]\n",
        "\n",
        "    preds = prediction_model.predict(X_data)\n",
        "    pred_texts = decode_batch_predictions(preds)\n",
        "\n",
        "    orig_texts = []\n",
        "    for label in labels:\n",
        "        text = \"\".join([labels_to_char[int(x)] for x in label])\n",
        "        orig_texts.append(text)\n",
        "\n",
        "    for i in range(bs):\n",
        "        print(f\"Ground truth: {orig_texts[i]} \\t Predicted: {pred_texts[i]}\")\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36LqYyxqmcO6"
      },
      "source": [
        "**Accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yXrOXFSTmcO7"
      },
      "source": [
        "decoded_text, actuals_text = get_all_preds(valid_data_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bM0XJNUCmcO_"
      },
      "source": [
        "print(f\"Validation Data Accuracy: {accuracy_score(actuals_text, decoded_text):.5f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgDlQwYvmcPL"
      },
      "source": [
        "**PostProcessing** \n",
        "* Predicted label length=9 - Remove the last 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-q0a6FCmmcPM"
      },
      "source": [
        "def remove_last_one(label):\n",
        "    idx = label.rfind(\"1\")\n",
        "    return label[:idx] + label[idx+1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "hNnoifrsmcPO"
      },
      "source": [
        "decoded_text = [remove_last_one(x) if len(x)==9 else x for x in decoded_text]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "OpIbSVZgmcPQ"
      },
      "source": [
        "print(f\"Validation Data Accuracy (Post Processing): {accuracy_score(actuals_text, decoded_text):.5f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "mDSa2qEKmcPR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vjwc0t-omcPT"
      },
      "source": [
        "### Training Data Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "mID8BqjLmcPU"
      },
      "source": [
        "decoded_text, actuals_text = get_all_preds(train_data_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "br3fSqOymcPY"
      },
      "source": [
        "print(f\"Training Data Accuracy: {accuracy_score(actuals_text, decoded_text):.5f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "hqSGF1F8mcPc"
      },
      "source": [
        "decoded_text = [remove_last_one(x) if len(x)==9 else x for x in decoded_text]\n",
        "print(f\"Training Data Accuracy (Post Processing): {accuracy_score(actuals_text, decoded_text):.5f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xeM7n_R7mcPf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hl7bA8_8mcPl"
      },
      "source": [
        "## Test Data Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "E0ThfKwnmcPl"
      },
      "source": [
        "test_df = pd.read_csv(\"raw/test_data/sample_submission.csv\")\n",
        "test_df[\"img_path\"] = test_df[\"tag\"].apply(lambda x: f\"processed/test/{x}.png\")\n",
        "test_df[\"label\"] = test_df[\"label\"].astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7VFKISfvmcP8"
      },
      "source": [
        "# Build testing data\n",
        "testing_data, testing_labels = generate_arrays(df=test_df)\n",
        "print(f\"# Test Images: {training_data.shape[0]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Uopzzb2rmcP-"
      },
      "source": [
        "test_data_generator = DataGenerator(data=testing_data,\n",
        "                                    labels=testing_labels, # fake labels\n",
        "                                    shuffle=False, \n",
        "                                    **params\n",
        "                                    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "VTUtGWmcmcQh"
      },
      "source": [
        "decoded_text, _ = get_all_preds(test_data_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6y6SGhhkmcQj"
      },
      "source": [
        "decoded_text = [remove_last_one(x) if len(x)==9 else x for x in decoded_text]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1SZHCLHqmcQo"
      },
      "source": [
        "len(testing_data), len(decoded_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "HEB_IxjVmcQv"
      },
      "source": [
        "plot_grid(testing_data, decoded_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KR8Newh8mcQx"
      },
      "source": [
        "plot_grid(testing_data, decoded_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "gkz3S0LvmcQy"
      },
      "source": [
        "submission = pd.DataFrame()\n",
        "submission[\"tag\"] = test_df[\"tag\"].tolist()\n",
        "submission[\"label\"] = decoded_text\n",
        "submission.to_csv(\"submission.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SaE02frymcQ4"
      },
      "source": [
        "submission.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bXUrMlktmcRC"
      },
      "source": [
        "submission.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vkUkuzatmcRF"
      },
      "source": [
        "submission[\"label\"].astype(str).str.len().value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLwjjRKomcRH"
      },
      "source": [
        "## Submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "eaYTuSUOmcRR"
      },
      "source": [
        "sub_json = submission.to_json()\n",
        "data = {\n",
        "    \"username\": \"aditya\",\n",
        "    \"password\": \"sdhjbj@8676\",\n",
        "    \"submission\": sub_json,\n",
        "    \"tag\": \"digits_v2\",\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "UdvyWlPBmcRT"
      },
      "source": [
        "r = requests.post(SUBMISSION_URL, json=data)\n",
        "r.text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "aSQ9KouEmcRW"
      },
      "source": [
        "rl = requests.post(LEADERBOARD_URL, json={})\n",
        "pprint(rl.json())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9BwqFny7mcRY"
      },
      "source": [
        "!rm -r raw external processed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "RJS4SbptmcRa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}